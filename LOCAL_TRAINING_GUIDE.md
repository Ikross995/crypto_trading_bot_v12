# üöÄ –õ–æ–∫–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ GRU –º–æ–¥–µ–ª–∏ - –ü–æ—à–∞–≥–æ–≤–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è

## üìã –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

### –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ:
- **Python:** 3.8+
- **RAM:** 8 GB
- **–ú–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ:** 5 GB —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ
- **–ò–Ω—Ç–µ—Ä–Ω–µ—Ç:** –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å Binance

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ (–¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è):
- **GPU:** NVIDIA GTX 1060+ (6GB+ VRAM)
- **RAM:** 16 GB
- **–ú–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ:** 10 GB

---

## üîß –®–∞–≥ 1: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

### Windows (—Å GPU NVIDIA):

```powershell
# 1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ PyTorch —Å CUDA –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# 2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install scikit-learn pandas numpy aiohttp

# 3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ GPU
python check_gpu.py
```

### Windows (–±–µ–∑ GPU / CPU only):

```powershell
# 1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ PyTorch CPU –≤–µ—Ä—Å–∏—é (–±—ã—Å—Ç—Ä–µ–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∞)
pip install torch torchvision

# 2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install scikit-learn pandas numpy aiohttp
```

### Linux / Mac:

```bash
# –° GPU (NVIDIA):
pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# –ë–µ–∑ GPU (CPU only):
pip3 install torch torchvision

# –û—Å—Ç–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
pip3 install scikit-learn pandas numpy aiohttp
```

---

## ‚úÖ –®–∞–≥ 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏

–ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–æ–≤–µ—Ä–∫—É GPU (–µ—Å–ª–∏ –µ—Å—Ç—å):

```bash
python check_gpu.py
```

**–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥ (—Å GPU):**
```
‚úÖ GPU available: NVIDIA GeForce RTX 5070 Ti
   GPU Memory: 16.0 GB
   CUDA Version: 12.1
```

**–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥ (CPU only):**
```
üìä Using CPU
   Training will be slower, but works fine!
```

---

## üéØ –®–∞–≥ 3: –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è

### –í–∞—Ä–∏–∞–Ω—Ç 1: –£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è (–†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø) ‚≠ê

–≠—Ç–æ **–ª—É—á—à–∞—è –≤–µ—Ä—Å–∏—è** —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –≤—Å–µ—Ö –±–∞–≥–æ–≤ ML!

```bash
# –° –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (365 –¥–Ω–µ–π, 50 —ç–ø–æ—Ö):
python examples/gru_training_improved.py

# –° –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (180 –¥–Ω–µ–π, 30–º —Ç–∞–π–º—Ñ—Ä–µ–π–º):
python examples/gru_training_improved.py --days 180 --interval 30m --epochs 50 --batch-size 128
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- `--days 180` - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 180 –¥–Ω–µ–π –¥–∞–Ω–Ω—ã—Ö (–ø–æ–ª–≥–æ–¥–∞)
- `--interval 30m` - –¢–∞–π–º—Ñ—Ä–µ–π–º 30 –º–∏–Ω—É—Ç
- `--epochs 50` - –ú–∞–∫—Å–∏–º—É–º 50 —ç–ø–æ—Ö (–æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —Ä–∞–Ω—å—à–µ —Å early stopping)
- `--batch-size 128` - –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç GPU)

**–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ batch sizes:**
- **RTX 5070 Ti (16GB):** `--batch-size 256` ‚ö°
- **RTX 4090 (24GB):** `--batch-size 512` ‚ö°‚ö°
- **RTX 3080 (10GB):** `--batch-size 128`
- **GTX 1080 (8GB):** `--batch-size 64`
- **CPU only:** `--batch-size 32`

---

### –í–∞—Ä–∏–∞–Ω—Ç 2: Percentage-based –≤–µ—Ä—Å–∏—è

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç % –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤–º–µ—Å—Ç–æ –∞–±—Å–æ–ª—é—Ç–Ω—ã—Ö —Ü–µ–Ω (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ –¥–ª—è –≤—Å–µ—Ö –º–æ–Ω–µ—Ç):

```bash
python examples/gru_training_pytorch_v2_percentage.py --days 180 --interval 30m --epochs 30 --batch-size 1024
```

---

### –í–∞—Ä–∏–∞–Ω—Ç 3: –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è (–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è)

```bash
python train_gru_final.py --days 180 --epochs 30 --batch-size 1024
```

---

## ‚è±Ô∏è –û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è

### –° GPU:
| GPU | Batch Size | 180 –¥–Ω–µ–π, 50 —ç–ø–æ—Ö | 365 –¥–Ω–µ–π, 50 —ç–ø–æ—Ö |
|-----|------------|-------------------|-------------------|
| **RTX 5070 Ti (16GB)** | 256 | ~30-40 –º–∏–Ω | ~1-2 —á–∞—Å–∞ |
| **RTX 4090 (24GB)** | 512 | ~20-30 –º–∏–Ω | ~40-60 –º–∏–Ω |
| **RTX 3080 (10GB)** | 128 | ~1-1.5 —á–∞—Å–∞ | ~2-3 —á–∞—Å–∞ |
| **GTX 1080 (8GB)** | 64 | ~2-3 —á–∞—Å–∞ | ~4-6 —á–∞—Å–æ–≤ |

### –° CPU:
| CPU | 180 –¥–Ω–µ–π | 365 –¥–Ω–µ–π |
|-----|----------|----------|
| **i7/i9 (8+ cores)** | ~4-6 —á–∞—Å–æ–≤ | ~8-12 —á–∞—Å–æ–≤ |
| **i5 (4-6 cores)** | ~8-10 —á–∞—Å–æ–≤ | ~16-20 —á–∞—Å–æ–≤ |

---

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è

–í–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –≤—ã —É–≤–∏–¥–∏—Ç–µ:

```
================================================================================
üöÄ IMPROVED GRU Model Training (NO BUGS!)
================================================================================
üìã Configuration:
   Symbols: BTCUSDT, ETHUSDT, BNBUSDT, ...
   Days: 180 (last 180 days of FRESH data)
   Sequence: 60
   Epochs: 50 (max, with early stopping)
   Batch size: 128
================================================================================

üéÆ Configuring GPU...
‚úÖ GPU: NVIDIA GeForce RTX 5070 Ti (16.0 GB)
   CUDA: 12.1

üì• Downloading BTCUSDT (1/10)...
   ‚úÖ BTCUSDT: 8,640 candles

üì¶ Preparing sequences (NO LEAKAGE!)...
   Sequence length: 60
   Train: 70%, Val: 15%, Test: 15%

‚úÖ Temporal split:
   Train: 6,048 samples
   Val:   1,296 samples
   Test:  1,296 samples

üß† Building IMPROVED GRU model...
‚úÖ Model parameters: 150,284

üéØ Training IMPROVED model...
   Epochs: 50 (max)
   Initial LR: 0.001
   Early stopping patience: 7

Epoch   1/50 | Train: 0.001234 | Val: 0.001456 | LR: 0.001000 | Time: 12.3s
Epoch   2/50 | Train: 0.001089 | Val: 0.001234 | LR: 0.001000 | Time: 24.8s
   üíæ New best model! Val Loss: 0.001234
Epoch   3/50 | Train: 0.000987 | Val: 0.001123 | LR: 0.001000 | Time: 37.2s
   üíæ New best model! Val Loss: 0.001123
...
   ‚ö†Ô∏è  EarlyStopping counter: 1/7
...
‚úÖ Early stopping at epoch 28
   Best validation loss: 0.000856

================================================================================
üìä Final Evaluation on Test Set
================================================================================
üìä Test Metrics (Real Prices):
   MSE:  125.45
   MAE:  $8.32
   MAPE: 0.15%

üìä Win Rate Analysis:
   Overall: 57.23% (742/1296)
   Significant moves (>0.0001): 58.91%

‚úÖ Model saved: models/checkpoints/gru_improved.pt
   Size: 2.3 MB

================================================================================
üéâ IMPROVED TRAINING COMPLETED!
================================================================================
```

---

## üéØ –ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è

–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ `models/checkpoints/gru_improved.pt`

### –û–±–Ω–æ–≤–∏—Ç–µ .env —Ñ–∞–π–ª:

```env
# –í–∫–ª—é—á–∏—Ç–µ GRU –º–æ–¥–µ–ª—å
GRU_ENABLE=true

# –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
GRU_MODEL_PATH=models/checkpoints/gru_improved.pt
```

### –ó–∞–ø—É—Å—Ç–∏—Ç–µ –±–æ—Ç–∞:

```bash
python start_bot.py
```

–∏–ª–∏

```bash
python cli.py live --timeframe 30m --use-imba
```

---

## üêõ Troubleshooting

### –û—à–∏–±–∫–∞: "CUDA out of memory"

**–†–µ—à–µ–Ω–∏–µ:** –£–º–µ–Ω—å—à–∏—Ç–µ batch size:
```bash
python examples/gru_training_improved.py --batch-size 64
# –ò–ª–∏ –µ—â—ë –º–µ–Ω—å—à–µ: --batch-size 32
```

---

### –û—à–∏–±–∫–∞: "No module named 'torch'"

**–†–µ—à–µ–Ω–∏–µ:** –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ PyTorch:
```bash
# –° GPU:
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# –ë–µ–∑ GPU:
pip install torch torchvision
```

---

### –û—à–∏–±–∫–∞: "Failed to download data from Binance"

**–ü—Ä–∏—á–∏–Ω—ã:**
1. –ù–µ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞
2. Binance API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ –≤–∞—à–µ–π —Å—Ç—Ä–∞–Ω–µ
3. Rate limit (—Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤)

**–†–µ—à–µ–Ω–∏–µ:**
1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç
2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ VPN (–µ—Å–ª–∏ Binance –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω)
3. –ü–æ–¥–æ–∂–¥–∏—Ç–µ 1 –º–∏–Ω—É—Ç—É –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞

---

### –û–±—É—á–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ–µ –Ω–∞ CPU

**–†–µ—à–µ–Ω–∏–µ:** –£–º–µ–Ω—å—à–∏—Ç–µ –æ–±—ä—ë–º –¥–∞–Ω–Ω—ã—Ö:
```bash
python examples/gru_training_improved.py --days 90 --epochs 20 --batch-size 32
```

---

### –û—à–∏–±–∫–∞: "No GPU found, using CPU"

–≠—Ç–æ **–Ω–µ –æ—à–∏–±–∫–∞**, –ø—Ä–æ—Å—Ç–æ PyTorch –Ω–µ –≤–∏–¥–∏—Ç GPU.

**–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:**
1. –£ –≤–∞—Å NVIDIA GPU? (AMD –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è PyTorch CUDA)
2. –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –¥—Ä–∞–π–≤–µ—Ä—ã NVIDIA?
3. –£—Å—Ç–∞–Ω–æ–≤–∏–ª–∏ PyTorch —Å CUDA?

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch —Å CUDA:**
```bash
pip uninstall torch torchvision
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
```

---

## üìà –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–π –æ–±—É—á–µ–Ω–∏—è

| –í–µ—Ä—Å–∏—è | –§–∞–π–ª | –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ | –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ |
|--------|------|--------------|------------|
| **Improved** ‚≠ê | `examples/gru_training_improved.py` | ‚úÖ NO data leakage<br>‚úÖ Temporal split<br>‚úÖ Early stopping<br>‚úÖ LR scheduler<br>‚úÖ RobustScaler | –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –∞–±—Å–æ–ª—é—Ç–Ω—É—é —Ü–µ–Ω—É |
| **Percentage** | `examples/gru_training_pytorch_v2_percentage.py` | ‚úÖ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ –¥–ª—è –≤—Å–µ—Ö –º–æ–Ω–µ—Ç<br>‚úÖ –ë–æ–ª—å—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (400K params) | ‚ùå –ï—Å—Ç—å data leakage<br>‚ùå –ù–µ—Ç early stopping |
| **Final** | `train_gru_final.py` | ‚úÖ –ö–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç percentage + enhanced | ‚ùå –ï—Å—Ç—å data leakage |

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ **Improved** –≤–µ—Ä—Å–∏—é –¥–ª—è production!

---

## üí° –°–æ–≤–µ—Ç—ã –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

### 1. –ë—ã—Å—Ç—Ä–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:
```bash
# –ú–∞–ª–µ–Ω—å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç, –±—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ:
python examples/gru_training_improved.py --days 30 --epochs 10 --batch-size 64
```

### 2. –ü–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ):
```bash
# –ì–æ–¥ –¥–∞–Ω–Ω—ã—Ö, 50 —ç–ø–æ—Ö, –±–æ–ª—å—à–æ–π batch:
python examples/gru_training_improved.py --days 365 --epochs 50 --batch-size 256
```

### 3. –î–ª—è —Å–ª–∞–±–æ–≥–æ GPU (8GB):
```bash
# –ù–µ–±–æ–ª—å—à–æ–π batch, –º–µ–Ω—å—à–µ –¥–∞–Ω–Ω—ã—Ö:
python examples/gru_training_improved.py --days 180 --epochs 30 --batch-size 64
```

### 4. –î–ª—è –º–æ—â–Ω–æ–≥–æ GPU (24GB+):
```bash
# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å:
python examples/gru_training_improved.py --days 365 --epochs 50 --batch-size 512
```

---

## üéì –ß—Ç–æ –¥–∞–ª—å—à–µ?

–ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏:

1. ‚úÖ **–û–±–Ω–æ–≤–∏—Ç–µ .env** - –≤–∫–ª—é—á–∏—Ç–µ GRU_ENABLE=true
2. ‚úÖ **–ó–∞–ø—É—Å—Ç–∏—Ç–µ –±–æ—Ç–∞** - `python start_bot.py`
3. ‚úÖ **–ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã** - —Å–º–æ—Ç—Ä–∏—Ç–µ –ª–æ–≥–∏ –∏ –º–µ—Ç—Ä–∏–∫–∏
4. ‚úÖ **–ü–µ—Ä–µ–æ–±—É—á–∞–π—Ç–µ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏** - –∫–∞–∂–¥—ã–µ 2-4 –Ω–µ–¥–µ–ª–∏ —Å–æ —Å–≤–µ–∂–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏

---

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

- **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è PyTorch:** https://pytorch.org/docs/stable/index.html
- **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è Binance API:** https://binance-docs.github.io/apidocs/
- **–ü—Ä–æ–±–ª–µ–º—ã —Å –æ–±—É—á–µ–Ω–∏–µ–º?** –°–æ–∑–¥–∞–π—Ç–µ issue –≤ GitHub

---

## ‚ú® –ö–ª—é—á–µ–≤—ã–µ —É–ª—É—á—à–µ–Ω–∏—è –≤ `gru_training_improved.py`

1. **NO data leakage** - scaler fit —Ç–æ–ª—å–∫–æ –Ω–∞ train –¥–∞–Ω–Ω—ã—Ö
2. **Temporal split** - train/val/test –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (70/15/15)
3. **shuffle=False** - —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–æ—Ä—è–¥–æ–∫
4. **Early stopping** - –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è –ø—Ä–∏ plateau (patience=7)
5. **Learning rate scheduler** - —É–º–µ–Ω—å—à–∞–µ—Ç LR –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
6. **Gradient clipping** - –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç exploding gradients
7. **RobustScaler** - —É—Å—Ç–æ–π—á–∏–≤ –∫ –≤—ã–±—Ä–æ—Å–∞–º
8. **AdamW optimizer** - –ª—É—á—à–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
9. **Dropout 0.4** - –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç overfitting
10. **Batch Normalization** - —Å—Ç–∞–±–∏–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ

---

üéâ **–£–¥–∞—á–∏ —Å –æ–±—É—á–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–∏!** üöÄ
