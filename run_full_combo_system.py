#!/usr/bin/env python3
"""
ğŸš€ğŸš€ğŸš€ ĞŸĞĞ›ĞĞ«Ğ™ Ğ—ĞĞŸĞ£Ğ¡Ğš COMBO Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞ« ğŸš€ğŸš€ğŸš€
========================================

ĞœĞĞšĞ¡Ğ˜ĞœĞĞ›Ğ¬ĞĞ«Ğ™ Ğ Ğ•Ğ–Ğ˜Ğœ - Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°ĞµÑ‚ Ğ’Ğ¡Ğ!

Pipeline:
1. ğŸ“¥ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
2. ğŸ¯ ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ensemble (5 Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹)
3. ğŸ¤– ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ RL Agent
4. ğŸ”„ Walk-Forward Optimization
5. ğŸ“Š Performance Analysis
6. ğŸ§  Meta-Learner Integration
7. ğŸ§ª Full System Backtest

Ğ’Ñ€ĞµĞ¼Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ: ~2-4 Ñ‡Ğ°ÑĞ° (Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ñ‚ Ğ¾Ñ‚ Ğ¶ĞµĞ»ĞµĞ·Ğ°)

ĞĞ²Ñ‚Ğ¾Ñ€: Claude (Anthropic)
"""

import asyncio
import logging
import sys
import time
from pathlib import Path
from datetime import datetime
import numpy as np
import pandas as pd

sys.path.insert(0, str(Path(__file__).parent))

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


# ==========================================
# ğŸ¯ MAIN ORCHESTRATOR
# ==========================================

async def run_full_combo_system(
    symbols: list = None,
    days: int = 365,
    interval: str = '30m',
    quick_mode: bool = False
):
    """
    ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¿ÑƒÑĞº COMBO ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹

    Args:
        symbols: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
        days: Ğ”Ğ½ĞµĞ¹ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸
        interval: Ğ¢Ğ°Ğ¹Ğ¼Ñ„Ñ€ĞµĞ¹Ğ¼
        quick_mode: Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼ (Ğ¼ĞµĞ½ÑŒÑˆĞµ ÑĞ¿Ğ¾Ñ…, Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ°)
    """
    if symbols is None:
        symbols = ['BTCUSDT', 'ETHUSDT', 'BNBUSDT']

    start_time = time.time()

    logger.info("=" * 100)
    logger.info("ğŸš€ğŸš€ğŸš€ ĞŸĞĞ›ĞĞ«Ğ™ Ğ—ĞĞŸĞ£Ğ¡Ğš COMBO Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞ« ğŸš€ğŸš€ğŸš€")
    logger.info("=" * 100)
    logger.info(f"ğŸ“‹ Configuration:")
    logger.info(f"   Symbols: {', '.join(symbols)}")
    logger.info(f"   Days: {days}")
    logger.info(f"   Interval: {interval}")
    logger.info(f"   Quick mode: {quick_mode}")
    logger.info(f"   Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("=" * 100)

    results = {}

    # ==========================================
    # STEP 1: Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
    # ==========================================
    logger.info("\n" + "ğŸ”¥" * 50)
    logger.info("STEP 1/7: ğŸ“¥ Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ Ğ”ĞĞĞĞ«Ğ¥")
    logger.info("ğŸ”¥" * 50)

    from examples.gru_training_pytorch import (
        BinanceDataDownloader,
        calculate_technical_indicators
    )

    downloader = BinanceDataDownloader()
    all_data = []

    for i, symbol in enumerate(symbols, 1):
        logger.info(f"ğŸ“¥ Downloading {symbol} ({i}/{len(symbols)})...")
        df = await downloader.download_historical_data(symbol, interval, days)
        if len(df) > 0:
            df = calculate_technical_indicators(df)
            all_data.append(df)
            logger.info(f"   âœ… {symbol}: {len(df):,} candles")

    combined_df = pd.concat(all_data, ignore_index=False)
    logger.info(f"\nâœ… Total data: {len(combined_df):,} samples")

    # Prepare features
    feature_columns = [
        'open', 'high', 'low', 'volume',
        'rsi', 'macd', 'macd_signal',
        'bb_upper', 'bb_mid', 'bb_lower',
        'sma_20', 'sma_50', 'ema_50',
        'volume_sma', 'atr',
        'volume_delta', 'obv', 'volume_ratio',
        'volume_spike', 'mfi', 'cvd', 'vwap_distance'
    ]

    # Prepare sequences for ML models
    from examples.gru_training_improved import prepare_sequences_no_leakage

    logger.info("\nğŸ“¦ Preparing sequences...")
    X_train, X_val, X_test, y_train, y_val, y_test, feature_scaler, target_scaler = \
        prepare_sequences_no_leakage(
            combined_df.copy(),
            feature_columns,
            sequence_length=60,
            train_ratio=0.7,
            val_ratio=0.15
        )

    results['data'] = {
        'train_samples': len(X_train),
        'val_samples': len(X_val),
        'test_samples': len(X_test),
        'features': len(feature_columns)
    }

    logger.info(f"âœ… Data prepared!")
    logger.info(f"   Train: {len(X_train):,}")
    logger.info(f"   Val: {len(X_val):,}")
    logger.info(f"   Test: {len(X_test):,}")

    # ==========================================
    # STEP 2: Ensemble Training
    # ==========================================
    logger.info("\n" + "ğŸ”¥" * 50)
    logger.info("STEP 2/7: ğŸ¯ ENSEMBLE TRAINING (5 Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹)")
    logger.info("ğŸ”¥" * 50)

    from examples.ensemble_trainer import EnsembleTrainer

    ensemble = EnsembleTrainer()

    ensemble_epochs = 10 if quick_mode else 30
    logger.info(f"ğŸ¯ Training {len(ensemble.configs)} models for {ensemble_epochs} epochs each...")

    ensemble_start = time.time()
    ensemble_results = await ensemble.train_ensemble(
        train_data=(X_train, y_train),
        val_data=(X_val, y_val),
        epochs=ensemble_epochs,
        batch_size=256
    )
    ensemble_time = time.time() - ensemble_start

    # Save ensemble
    ensemble.save_ensemble('models/combo_ensemble/')

    results['ensemble'] = {
        'training_time': ensemble_time,
        'num_models': len(ensemble.models),
        'model_weights': ensemble.model_weights,
        'best_model': min(ensemble.model_performance, key=ensemble.model_performance.get)
    }

    logger.info(f"\nâœ… Ensemble trained in {ensemble_time/60:.1f} minutes")
    logger.info(f"   Models: {len(ensemble.models)}")
    logger.info(f"   Best model: {results['ensemble']['best_model']}")

    # ==========================================
    # STEP 3: RL Agent Training
    # ==========================================
    logger.info("\n" + "ğŸ”¥" * 50)
    logger.info("STEP 3/7: ğŸ¤– RL AGENT TRAINING")
    logger.info("ğŸ”¥" * 50)

    from examples.rl_trading_agent import train_rl_agent

    rl_episodes = 50 if quick_mode else 100
    logger.info(f"ğŸ¤– Training RL Agent for {rl_episodes} episodes...")

    rl_start = time.time()
    rl_agent = await train_rl_agent(
        symbols=symbols,
        days=days,
        interval=interval,
        episodes=rl_episodes,
        save_path='models/combo_rl_agent.pt'
    )
    rl_time = time.time() - rl_start

    results['rl_agent'] = {
        'training_time': rl_time,
        'episodes': rl_episodes
    }

    logger.info(f"\nâœ… RL Agent trained in {rl_time/60:.1f} minutes")

    # ==========================================
    # STEP 4: Walk-Forward Optimization
    # ==========================================
    logger.info("\n" + "ğŸ”¥" * 50)
    logger.info("STEP 4/7: ğŸ”„ WALK-FORWARD OPTIMIZATION")
    logger.info("ğŸ”¥" * 50)

    # Simplified walk-forward (just split data and analyze)
    logger.info("ğŸ”„ Analyzing model on different time windows...")

    # Split data into windows
    window_size = len(combined_df) // 5  # 5 windows
    walk_forward_results = []

    for i in range(5):
        start_idx = i * window_size
        end_idx = min((i + 2) * window_size, len(combined_df))

        window_data = combined_df.iloc[start_idx:end_idx]

        if len(window_data) > 1000:
            # Calculate simple metrics for this window
            returns = window_data['close'].pct_change() * 100
            volatility = returns.std()
            trend = (window_data['close'].iloc[-1] - window_data['close'].iloc[0]) / window_data['close'].iloc[0] * 100

            walk_forward_results.append({
                'window': i + 1,
                'samples': len(window_data),
                'volatility': volatility,
                'trend': trend,
                'start': window_data.index[0],
                'end': window_data.index[-1]
            })

            logger.info(
                f"   Window {i+1}: {len(window_data):,} samples, "
                f"Trend={trend:+.1f}%, Vol={volatility:.2f}%"
            )

    results['walk_forward'] = {
        'windows': len(walk_forward_results),
        'results': walk_forward_results
    }

    logger.info(f"\nâœ… Walk-Forward analysis completed")
    logger.info(f"   Windows analyzed: {len(walk_forward_results)}")

    # ==========================================
    # STEP 5: Performance Analysis
    # ==========================================
    logger.info("\n" + "ğŸ”¥" * 50)
    logger.info("STEP 5/7: ğŸ“Š PERFORMANCE ANALYSIS")
    logger.info("ğŸ”¥" * 50)

    from examples.performance_analyzer import (
        PerformanceAnalyzer,
        TradeAnalysis
    )

    analyzer = PerformanceAnalyzer()

    # Generate sample trades for demo
    logger.info("ğŸ“Š Generating sample trading performance...")

    np.random.seed(42)
    for i in range(100):
        # Simulate trade based on actual data
        idx = np.random.randint(0, len(combined_df) - 100)
        entry_data = combined_df.iloc[idx]
        exit_data = combined_df.iloc[idx + 50]

        price_change = (exit_data['close'] - entry_data['close']) / entry_data['close'] * 100
        success = price_change > 0

        trade = TradeAnalysis(
            trade_id=i,
            entry_time=str(entry_data.name),
            exit_time=str(exit_data.name),
            direction='LONG' if i % 2 == 0 else 'SHORT',
            entry_price=float(entry_data['close']),
            exit_price=float(exit_data['close']),
            profit_pct=float(price_change),
            profit_usd=float(price_change * 100),
            hold_time_minutes=50 * 30,  # 30m intervals
            hour_of_day=entry_data.name.hour if hasattr(entry_data.name, 'hour') else 12,
            day_of_week=entry_data.name.dayofweek if hasattr(entry_data.name, 'dayofweek') else 1,
            volatility=float(np.random.uniform(0.2, 0.8)),
            trend='UP' if price_change > 0 else 'DOWN',
            rsi=float(entry_data.get('rsi', 50)),
            macd=float(entry_data.get('macd', 0)),
            bb_position=float(np.random.uniform(-1, 1)),
            success=success
        )

        analyzer.add_trade(trade)

    # Analyze
    perf_results = analyzer.analyze()

    # Save
    analyzer.save_analysis('data/combo_performance_analysis.json')

    results['performance'] = {
        'total_trades': len(analyzer.trades),
        'win_rate': perf_results['overall']['win_rate'],
        'sharpe_ratio': perf_results['overall']['sharpe_ratio'],
        'recommendations': len(perf_results['recommendations'])
    }

    logger.info(f"\nâœ… Performance analysis completed")
    logger.info(f"   Trades analyzed: {len(analyzer.trades)}")
    logger.info(f"   Win Rate: {perf_results['overall']['win_rate']:.2f}%")

    # ==========================================
    # STEP 6: Meta-Learner Integration
    # ==========================================
    logger.info("\n" + "ğŸ”¥" * 50)
    logger.info("STEP 6/7: ğŸ§  META-LEARNER INTEGRATION")
    logger.info("ğŸ”¥" * 50)

    from examples.meta_learner import MetaLearner

    meta = MetaLearner()

    # Load all trained components
    logger.info("ğŸ§  Loading all trained models into Meta-Learner...")
    meta.load_models(
        rl_agent_path='models/combo_rl_agent.pt',
        ensemble_path='models/combo_ensemble/',
        walk_forward_path='models/combo_ensemble/'  # Using ensemble as placeholder
    )

    logger.info(f"âœ… Meta-Learner initialized with {len(meta.models)} strategies")

    # ==========================================
    # STEP 7: Full System Backtest
    # ==========================================
    logger.info("\n" + "ğŸ”¥" * 50)
    logger.info("STEP 7/7: ğŸ§ª FULL SYSTEM BACKTEST")
    logger.info("ğŸ”¥" * 50)

    logger.info("ğŸ§ª Running backtest with Meta-Learner...")

    backtest_results = await meta.backtest(
        data=combined_df,
        window_size=500,
        step_size=50
    )

    # Save meta-learner state
    meta.save_state('data/combo_meta_learner_state.json')

    results['meta_learner'] = {
        'strategies_loaded': len(meta.models),
        'backtest_trades': len(backtest_results['trades'])
    }

    logger.info(f"\nâœ… Full system backtest completed")
    logger.info(f"   Trades simulated: {len(backtest_results['trades'])}")

    # ==========================================
    # FINAL SUMMARY
    # ==========================================
    total_time = time.time() - start_time

    logger.info("\n\n" + "=" * 100)
    logger.info("ğŸ‰ğŸ‰ğŸ‰ COMBO Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞ ĞŸĞĞ›ĞĞĞ¡Ğ¢Ğ¬Ğ® ĞĞ‘Ğ£Ğ§Ğ•ĞĞ! ğŸ‰ğŸ‰ğŸ‰")
    logger.info("=" * 100)

    logger.info(f"\nâ±ï¸  Ğ’Ğ Ğ•ĞœĞ¯ Ğ’Ğ«ĞŸĞĞ›ĞĞ•ĞĞ˜Ğ¯:")
    logger.info(f"   Total: {total_time/60:.1f} minutes ({total_time/3600:.2f} hours)")
    logger.info(f"   Ensemble: {results['ensemble']['training_time']/60:.1f} min")
    logger.info(f"   RL Agent: {results['rl_agent']['training_time']/60:.1f} min")

    logger.info(f"\nğŸ“Š ĞšĞĞœĞŸĞĞĞ•ĞĞ¢Ğ«:")
    logger.info(f"   âœ… Ensemble: {results['ensemble']['num_models']} models trained")
    logger.info(f"   âœ… RL Agent: {results['rl_agent']['episodes']} episodes")
    logger.info(f"   âœ… Walk-Forward: {results['walk_forward']['windows']} windows analyzed")
    logger.info(f"   âœ… Performance: {results['performance']['total_trades']} trades analyzed")
    logger.info(f"   âœ… Meta-Learner: {results['meta_learner']['strategies_loaded']} strategies loaded")

    logger.info(f"\nğŸ“ˆ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ«:")
    logger.info(f"   Win Rate (sample): {results['performance']['win_rate']:.2f}%")
    logger.info(f"   Sharpe Ratio: {results['performance']['sharpe_ratio']:.2f}")

    logger.info(f"\nğŸ’¾ SAVED FILES:")
    logger.info(f"   âœ… models/combo_ensemble/ - Ensemble models")
    logger.info(f"   âœ… models/combo_rl_agent.pt - RL Agent")
    logger.info(f"   âœ… data/combo_performance_analysis.json - Performance analysis")
    logger.info(f"   âœ… data/combo_meta_learner_state.json - Meta-Learner state")

    logger.info(f"\nğŸš€ NEXT STEPS:")
    logger.info(f"   1. Review performance analysis:")
    logger.info(f"      cat data/combo_performance_analysis.json")
    logger.info(f"")
    logger.info(f"   2. Test predictions with Meta-Learner:")
    logger.info(f"      python -c \"from examples.meta_learner import MetaLearner; ...\"")
    logger.info(f"")
    logger.info(f"   3. Deploy to production (with risk management!)")

    logger.info("\n" + "=" * 100)
    logger.info("ğŸ’ª COMBO Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞ Ğ“ĞĞ¢ĞĞ’Ğ Ğš Ğ ĞĞ‘ĞĞ¢Ğ•!")
    logger.info("=" * 100)

    return results


# ==========================================
# ğŸš€ MAIN
# ==========================================

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="ğŸš€ ĞŸĞĞ›ĞĞ«Ğ™ Ğ—ĞĞŸĞ£Ğ¡Ğš COMBO Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞ«")
    parser.add_argument('--symbols', type=str, nargs='+',
                       default=['BTCUSDT', 'ETHUSDT', 'BNBUSDT'],
                       help='Trading symbols')
    parser.add_argument('--days', type=int, default=365,
                       help='Days of historical data')
    parser.add_argument('--interval', type=str, default='30m',
                       help='Timeframe (1m, 5m, 15m, 30m, 1h, 4h)')
    parser.add_argument('--quick', action='store_true',
                       help='Quick mode (fewer epochs, for testing)')

    args = parser.parse_args()

    logger.info("ğŸ”¥ Starting FULL COMBO SYSTEM...")
    logger.info(f"   Symbols: {args.symbols}")
    logger.info(f"   Quick mode: {args.quick}")

    asyncio.run(run_full_combo_system(
        symbols=args.symbols,
        days=args.days,
        interval=args.interval,
        quick_mode=args.quick
    ))
