#!/usr/bin/env python3
"""
üîÑ Walk-Forward Optimization System
====================================

ADAPTIVE LEARNING:
- –û–±—É—á–∞–µ—Ç –Ω–∞ —Å–∫–æ–ª—å–∑—è—â–µ–º –æ–∫–Ω–µ
- –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –Ω–∞ –±—É–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
- –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —á—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç
- –ê–¥–∞–ø—Ç–∏—Ä—É–µ—Ç—Å—è –∫ –∏–∑–º–µ–Ω—è—é—â–µ–º—É—Å—è —Ä—ã–Ω–∫—É
- –ò–∑–±–µ–≥–∞–µ—Ç overfitting

–ü—Ä–æ—Ü–µ—Å—Å:
1. Train –Ω–∞ Jan-Jun ‚Üí Test –Ω–∞ Jul
2. Train –Ω–∞ Feb-Jul ‚Üí Test –Ω–∞ Aug
3. Train –Ω–∞ Mar-Aug ‚Üí Test –Ω–∞ Sep
... –∏ —Ç–∞–∫ –¥–∞–ª–µ–µ

–í—ã–≥–æ–¥—ã:
- –í–∏–¥–∏–º —á—Ç–æ –†–ï–ê–õ–¨–ù–û —Ä–∞–±–æ—Ç–∞–µ—Ç
- –ê–¥–∞–ø—Ç–∞—Ü–∏—è –∫ —Ä—ã–Ω–∫—É
- –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
- –û–±—ä–µ–∫—Ç–∏–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞

–ê–≤—Ç–æ—Ä: Claude (Anthropic)
"""

import asyncio
import logging
import sys
import time
import json
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
import numpy as np
import pandas as pd
from dataclasses import dataclass, asdict

sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    import torch
except ImportError as e:
    print(f"‚ùå Import error: {e}")
    sys.exit(1)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


# ==========================================
# üìä RESULTS DATA CLASS
# ==========================================

@dataclass
class WalkForwardResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–¥–Ω–æ–≥–æ walk-forward —Ç–µ—Å—Ç–∞"""
    window_id: int
    train_start: str
    train_end: str
    test_start: str
    test_end: str

    # Training metrics
    train_samples: int
    test_samples: int
    training_time: float
    epochs_trained: int

    # Test performance
    win_rate: float
    sharpe_ratio: float
    total_return: float
    max_drawdown: float
    num_trades: int
    avg_profit: float
    profit_factor: float

    # Model info
    model_params: int
    best_val_loss: float

    # Market conditions
    market_volatility: float
    market_trend: float  # +1 bull, -1 bear, 0 sideways

    def to_dict(self):
        return asdict(self)


# ==========================================
# üîÑ WALK-FORWARD ENGINE
# ==========================================

class WalkForwardOptimizer:
    """
    Walk-Forward –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è —Ç–æ—Ä–≥–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π

    –ü—Ä–æ—Ü–µ—Å—Å:
    1. –†–∞–∑–±–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–∫–Ω–∞
    2. –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ train window
    3. –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –Ω–∞ test window (–±—É–¥—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ!)
    4. –°–¥–≤–∏–≥–∞–µ—Ç –æ–∫–Ω–æ –∏ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç
    5. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    """

    def __init__(
        self,
        train_window_months: int = 6,
        test_window_months: int = 1,
        step_months: int = 1,
        min_samples: int = 1000
    ):
        self.train_window_months = train_window_months
        self.test_window_months = test_window_months
        self.step_months = step_months
        self.min_samples = min_samples

        self.results: List[WalkForwardResult] = []

    def split_data(
        self,
        df: pd.DataFrame
    ) -> List[Tuple[pd.DataFrame, pd.DataFrame]]:
        """
        –†–∞–∑–±–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ walk-forward windows

        Returns:
            List of (train_df, test_df) tuples
        """
        windows = []

        # Ensure datetime index
        if not isinstance(df.index, pd.DatetimeIndex):
            df.index = pd.to_datetime(df.index)

        start_date = df.index.min()
        end_date = df.index.max()

        logger.info(f"üìÖ Data range: {start_date} ‚Üí {end_date}")
        logger.info(f"   Total samples: {len(df):,}")

        current_date = start_date

        window_id = 0
        while True:
            # Calculate window dates
            train_start = current_date
            train_end = train_start + pd.DateOffset(months=self.train_window_months)
            test_start = train_end
            test_end = test_start + pd.DateOffset(months=self.test_window_months)

            # Check if we have enough data
            if test_end > end_date:
                break

            # Get data for this window
            train_mask = (df.index >= train_start) & (df.index < train_end)
            test_mask = (df.index >= test_start) & (df.index < test_end)

            train_df = df[train_mask].copy()
            test_df = df[test_mask].copy()

            # Check minimum samples
            if len(train_df) < self.min_samples or len(test_df) < 100:
                logger.warning(
                    f"‚ö†Ô∏è  Window {window_id}: Insufficient data "
                    f"(train={len(train_df)}, test={len(test_df)})"
                )
                current_date += pd.DateOffset(months=self.step_months)
                window_id += 1
                continue

            windows.append((train_df, test_df))

            logger.info(
                f"‚úÖ Window {window_id}: "
                f"Train {train_start.strftime('%Y-%m-%d')} ‚Üí {train_end.strftime('%Y-%m-%d')} "
                f"({len(train_df):,} samples), "
                f"Test {test_start.strftime('%Y-%m-%d')} ‚Üí {test_end.strftime('%Y-%m-%d')} "
                f"({len(test_df):,} samples)"
            )

            # Move to next window
            current_date += pd.DateOffset(months=self.step_months)
            window_id += 1

        logger.info(f"üìä Created {len(windows)} walk-forward windows")

        return windows

    async def optimize(
        self,
        data: pd.DataFrame,
        symbols: List[str],
        train_func,  # Function to train model
        test_func,   # Function to test model
        hyperparams: Dict = None
    ) -> List[WalkForwardResult]:
        """
        –ó–∞–ø—É—Å—Ç–∏—Ç—å walk-forward optimization

        Args:
            data: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            symbols: –°–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª–æ–≤
            train_func: –§—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
            test_func: –§—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
            hyperparams: –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–æ–¥–µ–ª–µ–π

        Returns:
            List of WalkForwardResult
        """
        if hyperparams is None:
            hyperparams = {}

        windows = self.split_data(data)

        logger.info("=" * 80)
        logger.info("üîÑ WALK-FORWARD OPTIMIZATION STARTED")
        logger.info("=" * 80)
        logger.info(f"   Windows: {len(windows)}")
        logger.info(f"   Train window: {self.train_window_months} months")
        logger.info(f"   Test window: {self.test_window_months} month(s)")
        logger.info("=" * 80)

        for window_id, (train_df, test_df) in enumerate(windows):
            logger.info(f"\n{'='*80}")
            logger.info(f"üîÑ WINDOW {window_id + 1}/{len(windows)}")
            logger.info(f"{'='*80}")

            start_time = time.time()

            # Train model
            logger.info(f"üéØ Training model...")
            model, train_metrics = await train_func(
                train_df=train_df,
                val_split=0.15,
                **hyperparams
            )

            # Test model
            logger.info(f"üìä Testing model on future data...")
            test_metrics = await test_func(
                model=model,
                test_df=test_df
            )

            # Calculate market conditions
            market_metrics = self._analyze_market(test_df)

            # Store results
            result = WalkForwardResult(
                window_id=window_id + 1,
                train_start=train_df.index.min().strftime('%Y-%m-%d'),
                train_end=train_df.index.max().strftime('%Y-%m-%d'),
                test_start=test_df.index.min().strftime('%Y-%m-%d'),
                test_end=test_df.index.max().strftime('%Y-%m-%d'),
                train_samples=len(train_df),
                test_samples=len(test_df),
                training_time=time.time() - start_time,
                epochs_trained=train_metrics.get('epochs', 0),
                win_rate=test_metrics.get('win_rate', 0),
                sharpe_ratio=test_metrics.get('sharpe_ratio', 0),
                total_return=test_metrics.get('total_return', 0),
                max_drawdown=test_metrics.get('max_drawdown', 0),
                num_trades=test_metrics.get('num_trades', 0),
                avg_profit=test_metrics.get('avg_profit', 0),
                profit_factor=test_metrics.get('profit_factor', 0),
                model_params=train_metrics.get('model_params', 0),
                best_val_loss=train_metrics.get('best_val_loss', 0),
                market_volatility=market_metrics['volatility'],
                market_trend=market_metrics['trend']
            )

            self.results.append(result)

            # Log window results
            logger.info(f"üìà Window {window_id + 1} Results:")
            logger.info(f"   Win Rate: {result.win_rate:.2f}%")
            logger.info(f"   Total Return: {result.total_return:+.2f}%")
            logger.info(f"   Sharpe Ratio: {result.sharpe_ratio:+.2f}")
            logger.info(f"   Max Drawdown: {result.max_drawdown:.2f}%")
            logger.info(f"   Trades: {result.num_trades}")
            logger.info(f"   Market: {market_metrics['trend_label']} "
                       f"(vol={market_metrics['volatility']:.2f}%)")

        # Final summary
        self._print_summary()

        return self.results

    def _analyze_market(self, df: pd.DataFrame) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π"""
        returns = df['close'].pct_change() * 100
        volatility = returns.std()

        # Trend
        first_price = df['close'].iloc[0]
        last_price = df['close'].iloc[-1]
        total_return = (last_price - first_price) / first_price * 100

        if total_return > 5:
            trend = 1.0
            trend_label = "BULL üêÇ"
        elif total_return < -5:
            trend = -1.0
            trend_label = "BEAR üêª"
        else:
            trend = 0.0
            trend_label = "SIDEWAYS ‚ÜîÔ∏è"

        return {
            'volatility': volatility,
            'trend': trend,
            'trend_label': trend_label,
            'total_return': total_return
        }

    def _print_summary(self):
        """–í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        if not self.results:
            return

        logger.info("\n" + "=" * 80)
        logger.info("üìä WALK-FORWARD OPTIMIZATION SUMMARY")
        logger.info("=" * 80)

        # Overall stats
        avg_win_rate = np.mean([r.win_rate for r in self.results])
        avg_sharpe = np.mean([r.sharpe_ratio for r in self.results])
        avg_return = np.mean([r.total_return for r in self.results])
        total_return = sum([r.total_return for r in self.results])

        logger.info(f"üéØ Overall Performance:")
        logger.info(f"   Avg Win Rate: {avg_win_rate:.2f}%")
        logger.info(f"   Avg Sharpe: {avg_sharpe:+.2f}")
        logger.info(f"   Avg Return per window: {avg_return:+.2f}%")
        logger.info(f"   Total Return (sum): {total_return:+.2f}%")

        # Best/Worst windows
        best_window = max(self.results, key=lambda r: r.total_return)
        worst_window = min(self.results, key=lambda r: r.total_return)

        logger.info(f"\nüèÜ Best Window:")
        logger.info(f"   Window {best_window.window_id}: {best_window.total_return:+.2f}% "
                   f"(WR={best_window.win_rate:.1f}%, Sharpe={best_window.sharpe_ratio:+.2f})")

        logger.info(f"\nüìâ Worst Window:")
        logger.info(f"   Window {worst_window.window_id}: {worst_window.total_return:+.2f}% "
                   f"(WR={worst_window.win_rate:.1f}%, Sharpe={worst_window.sharpe_ratio:+.2f})")

        # Market condition analysis
        bull_results = [r for r in self.results if r.market_trend > 0]
        bear_results = [r for r in self.results if r.market_trend < 0]
        sideways_results = [r for r in self.results if r.market_trend == 0]

        if bull_results:
            bull_return = np.mean([r.total_return for r in bull_results])
            logger.info(f"\nüêÇ Bull Markets ({len(bull_results)} windows):")
            logger.info(f"   Avg Return: {bull_return:+.2f}%")

        if bear_results:
            bear_return = np.mean([r.total_return for r in bear_results])
            logger.info(f"\nüêª Bear Markets ({len(bear_results)} windows):")
            logger.info(f"   Avg Return: {bear_return:+.2f}%")

        if sideways_results:
            sideways_return = np.mean([r.total_return for r in sideways_results])
            logger.info(f"\n‚ÜîÔ∏è  Sideways Markets ({len(sideways_results)} windows):")
            logger.info(f"   Avg Return: {sideways_return:+.2f}%")

        # Robustness
        positive_windows = len([r for r in self.results if r.total_return > 0])
        robustness = positive_windows / len(self.results) * 100

        logger.info(f"\nüí™ Robustness:")
        logger.info(f"   Positive windows: {positive_windows}/{len(self.results)} ({robustness:.1f}%)")

        logger.info("=" * 80)

    def save_results(self, path: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON"""
        results_dict = [r.to_dict() for r in self.results]

        with open(path, 'w') as f:
            json.dump(results_dict, f, indent=2)

        logger.info(f"üíæ Results saved to {path}")

    def get_best_hyperparams(self) -> Dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å –ª—É—á—à–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            Dict —Å —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        """
        if not self.results:
            return {}

        # Find patterns
        high_sharpe_results = [r for r in self.results if r.sharpe_ratio > 1.0]

        if high_sharpe_results:
            # Analyze what worked
            avg_epochs = np.mean([r.epochs_trained for r in high_sharpe_results])

            recommendations = {
                'optimal_epochs': int(avg_epochs),
                'min_samples': self.min_samples,
                'retrain_frequency': f"{self.step_months} month(s)",
            }

            logger.info(f"üí° Recommendations based on {len(high_sharpe_results)} successful windows:")
            for key, val in recommendations.items():
                logger.info(f"   {key}: {val}")

            return recommendations

        return {}


# ==========================================
# üöÄ MAIN (EXAMPLE USAGE)
# ==========================================

async def run_walk_forward_example():
    """
    –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Walk-Forward Optimizer
    """
    # Import training functions
    from gru_training_improved import train_improved_gru

    # Load data
    from gru_training_pytorch import (
        BinanceDataDownloader,
        calculate_technical_indicators
    )

    symbols = ['BTCUSDT']
    downloader = BinanceDataDownloader()

    logger.info("üì• Loading data...")
    all_data = []
    for symbol in symbols:
        df = await downloader.download_historical_data(symbol, '30m', 365)
        if len(df) > 0:
            df = calculate_technical_indicators(df)
            all_data.append(df)

    data = pd.concat(all_data, ignore_index=False)

    # Define training function wrapper
    async def train_wrapper(train_df, val_split=0.15, **kwargs):
        """Wrapper –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è"""
        # Here you would call your actual training function
        # For now, return dummy metrics
        return None, {
            'epochs': 20,
            'model_params': 100000,
            'best_val_loss': 0.5
        }

    # Define testing function wrapper
    async def test_wrapper(model, test_df):
        """Wrapper –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        # Here you would test your model
        # For now, return dummy metrics
        return {
            'win_rate': np.random.uniform(45, 60),
            'sharpe_ratio': np.random.uniform(-1, 2),
            'total_return': np.random.uniform(-10, 15),
            'max_drawdown': np.random.uniform(-20, -5),
            'num_trades': int(np.random.uniform(10, 50)),
            'avg_profit': np.random.uniform(-1, 2),
            'profit_factor': np.random.uniform(0.8, 1.5)
        }

    # Create optimizer
    optimizer = WalkForwardOptimizer(
        train_window_months=6,
        test_window_months=1,
        step_months=1
    )

    # Run optimization
    results = await optimizer.optimize(
        data=data,
        symbols=symbols,
        train_func=train_wrapper,
        test_func=test_wrapper,
        hyperparams={
            'epochs': 50,
            'batch_size': 256
        }
    )

    # Save results
    optimizer.save_results('data/walk_forward_results.json')

    # Get recommendations
    optimizer.get_best_hyperparams()


if __name__ == "__main__":
    asyncio.run(run_walk_forward_example())
