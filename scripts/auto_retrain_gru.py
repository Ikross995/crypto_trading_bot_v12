#!/usr/bin/env python3
"""
‚è∞ Automatic GRU Model Retraining
=================================

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–æ–±—É—á–∞–µ—Ç GRU –º–æ–¥–µ–ª—å –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é.

–ó–∞–ø—É—Å–∫:
    # –ó–∞–ø—É—Å—Ç–∏—Ç—å –≤ —Ñ–æ–Ω–µ (–ø–µ—Ä–µ–æ–±—É—á–∞–µ—Ç –∫–∞–∂–¥–æ–µ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ –≤ 02:00)
    python scripts/auto_retrain_gru.py

    # –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å –¥—Ä—É–≥–∏–º —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ–º
    python scripts/auto_retrain_gru.py --schedule daily --time 03:00

    # –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–¥–∏–Ω —Ä–∞–∑ —Å–µ–π—á–∞—Å
    python scripts/auto_retrain_gru.py --run-now

–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ:
    - daily: –ö–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è
    - weekly: –ö–∞–∂–¥–æ–µ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ
    - monthly: 1-–≥–æ —á–∏—Å–ª–∞ –∫–∞–∂–¥–æ–≥–æ –º–µ—Å—è—Ü–∞

–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç:
    1. –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π –¥–∞–Ω–Ω—ã—Ö
    2. –î–æ—Ç—Ä–µ–Ω–∏—Ä–æ–≤—ã–≤–∞–µ—Ç –º–æ–¥–µ–ª—å 5 —ç–ø–æ—Ö
    3. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—É—é –º–æ–¥–µ–ª—å
    4. –°–æ–∑–¥–∞—ë—Ç —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Å—Ç–∞—Ä–æ–π –º–æ–¥–µ–ª–∏
"""

import asyncio
import argparse
import logging
import sys
import time
from pathlib import Path
from datetime import datetime, timezone
import schedule
import shutil

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞
sys.path.insert(0, str(Path(__file__).parent.parent))

# –ò–º–ø–æ—Ä—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –¥–æ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
from scripts.finetune_gru import finetune_model

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    handlers=[
        logging.FileHandler('logs/auto_retrain.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class AutoRetrainer:
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–µ–æ–±—É—á–∞—Ç–µ–ª—å GRU –º–æ–¥–µ–ª–∏.
    """

    def __init__(
        self,
        model_path: str = "models/checkpoints/gru_model_pytorch.pt",
        days: int = 30,
        epochs: int = 5,
        backup_dir: str = "models/backups"
    ):
        self.model_path = Path(model_path)
        self.days = days
        self.epochs = epochs
        self.backup_dir = Path(backup_dir)
        self.backup_dir.mkdir(parents=True, exist_ok=True)

    def create_backup(self):
        """–°–æ–∑–¥–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏"""
        if not self.model_path.exists():
            logger.warning(f"‚ö†Ô∏è  Model not found: {self.model_path}")
            return False

        # –ù–∞–∑–≤–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ —Å timestamp
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_path = self.backup_dir / f"gru_model_backup_{timestamp}.pt"

        # –ö–æ–ø–∏—Ä—É–µ–º
        shutil.copy2(self.model_path, backup_path)
        logger.info(f"üíæ Backup created: {backup_path}")

        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã (–æ—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5)
        self.cleanup_old_backups(keep=5)

        return True

    def cleanup_old_backups(self, keep: int = 5):
        """–£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã, –æ—Å—Ç–∞–≤–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N"""
        backups = sorted(self.backup_dir.glob("gru_model_backup_*.pt"))

        if len(backups) > keep:
            to_remove = backups[:-keep]
            for backup in to_remove:
                backup.unlink()
                logger.info(f"üóëÔ∏è  Removed old backup: {backup.name}")

    async def retrain(self):
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        logger.info("=" * 80)
        logger.info("‚è∞ AUTO-RETRAIN: Starting scheduled retraining")
        logger.info(f"   Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("=" * 80)

        try:
            # –°–æ–∑–¥–∞—ë–º –±—ç–∫–∞–ø
            logger.info("üíæ Creating backup of current model...")
            self.create_backup()

            # –î–æ—Ç—Ä–µ–Ω–∏—Ä–æ–≤—ã–≤–∞–µ–º –º–æ–¥–µ–ª—å
            logger.info(f"üîÑ Fine-tuning on last {self.days} days ({self.epochs} epochs)...")
            await finetune_model(
                model_path=str(self.model_path),
                symbols=None,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ –∂–µ —á—Ç–æ –∏ —Ä–∞–Ω—å—à–µ
                days=self.days,
                interval="1m",
                epochs=self.epochs,
                batch_size=32,
                learning_rate=0.0001,
                save_path=None  # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω—É—é –º–æ–¥–µ–ª—å
            )

            logger.info("=" * 80)
            logger.info("‚úÖ AUTO-RETRAIN: Completed successfully!")
            logger.info("=" * 80)

            return True

        except Exception as e:
            logger.error(f"‚ùå AUTO-RETRAIN: Failed with error: {e}")
            logger.error("   Model backup is available in backups directory")
            return False

    def run_sync(self):
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—ë—Ä—Ç–∫–∞ –¥–ª—è asyncio"""
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        result = loop.run_until_complete(self.retrain())
        loop.close()
        return result


def schedule_retraining(
    schedule_type: str = "weekly",
    time_str: str = "02:00",
    model_path: str = "models/checkpoints/gru_model_pytorch.pt",
    days: int = 30,
    epochs: int = 5
):
    """
    –ù–∞—Å—Ç—Ä–æ–∏—Ç—å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è.

    Args:
        schedule_type: 'daily', 'weekly', 'monthly'
        time_str: –í—Ä–µ–º—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ HH:MM
        model_path: –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
        days: –î–Ω–µ–π —Å–≤–µ–∂–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–æ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
        epochs: –≠–ø–æ—Ö –¥–æ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
    """
    logger.info("=" * 80)
    logger.info("‚è∞ AUTO-RETRAIN: Scheduler Started")
    logger.info("=" * 80)
    logger.info(f"üìã Configuration:")
    logger.info(f"   Schedule: {schedule_type}")
    logger.info(f"   Time: {time_str}")
    logger.info(f"   Model: {model_path}")
    logger.info(f"   Fresh data: {days} days")
    logger.info(f"   Epochs: {epochs}")
    logger.info("=" * 80)

    # –°–æ–∑–¥–∞—ë–º retrainer
    retrainer = AutoRetrainer(
        model_path=model_path,
        days=days,
        epochs=epochs
    )

    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ
    if schedule_type == "daily":
        schedule.every().day.at(time_str).do(retrainer.run_sync)
        logger.info(f"üìÖ Scheduled: Daily at {time_str}")

    elif schedule_type == "weekly":
        schedule.every().sunday.at(time_str).do(retrainer.run_sync)
        logger.info(f"üìÖ Scheduled: Every Sunday at {time_str}")

    elif schedule_type == "monthly":
        # –ë—É–¥–µ–º –ø—Ä–æ–≤–µ—Ä—è—Ç—å 1-–µ —á–∏—Å–ª–æ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è
        def monthly_task():
            if datetime.now().day == 1:
                retrainer.run_sync()

        schedule.every().day.at(time_str).do(monthly_task)
        logger.info(f"üìÖ Scheduled: 1st of every month at {time_str}")

    else:
        logger.error(f"‚ùå Unknown schedule type: {schedule_type}")
        return

    logger.info("")
    logger.info("üöÄ Scheduler is running... (Press Ctrl+C to stop)")
    logger.info(f"   Next run: {schedule.next_run()}")
    logger.info("")

    # –ó–∞–ø—É—Å–∫–∞–µ–º scheduler loop
    try:
        while True:
            schedule.run_pending()
            time.sleep(60)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É

    except KeyboardInterrupt:
        logger.info("")
        logger.info("=" * 80)
        logger.info("‚è∏Ô∏è  AUTO-RETRAIN: Scheduler stopped by user")
        logger.info("=" * 80)


def run_now(model_path: str, days: int, epochs: int):
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å"""
    logger.info("üöÄ Running retraining now...")

    retrainer = AutoRetrainer(
        model_path=model_path,
        days=days,
        epochs=epochs
    )

    success = retrainer.run_sync()

    if success:
        logger.info("‚úÖ Retraining completed successfully!")
    else:
        logger.error("‚ùå Retraining failed!")
        sys.exit(1)


def main():
    parser = argparse.ArgumentParser(description="Automatic GRU model retraining")

    parser.add_argument('--schedule', type=str, default='weekly',
                        choices=['daily', 'weekly', 'monthly'],
                        help='Retraining schedule (default: weekly)')
    parser.add_argument('--time', type=str, default='02:00',
                        help='Time to run (HH:MM format, default: 02:00)')
    parser.add_argument('--model', type=str, default='models/checkpoints/gru_model_pytorch.pt',
                        help='Path to model')
    parser.add_argument('--days', type=int, default=30,
                        help='Days of fresh data (default: 30)')
    parser.add_argument('--epochs', type=int, default=5,
                        help='Epochs for fine-tuning (default: 5)')
    parser.add_argument('--run-now', action='store_true',
                        help='Run retraining immediately instead of scheduling')

    args = parser.parse_args()

    # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ª–æ–≥–æ–≤
    Path('logs').mkdir(exist_ok=True)

    if args.run_now:
        # –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ–π—á–∞—Å
        run_now(args.model, args.days, args.epochs)
    else:
        # –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é
        schedule_retraining(
            schedule_type=args.schedule,
            time_str=args.time,
            model_path=args.model,
            days=args.days,
            epochs=args.epochs
        )


if __name__ == "__main__":
    main()
